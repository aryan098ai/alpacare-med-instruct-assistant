{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e069610f4b6446a98b4a4e4960bd70f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5221ca53dc7d4188b50776714ac8ecdb",
              "IPY_MODEL_f7930487dfe2475c84b639a8c4a125e2",
              "IPY_MODEL_26b3bb3a77754e7594f58cbc4f18c8b4"
            ],
            "layout": "IPY_MODEL_e396fac6f85645b1a8bcb1c03e4f0775"
          }
        },
        "5221ca53dc7d4188b50776714ac8ecdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d19cf0e2c25c4a638e48d61a60aaafde",
            "placeholder": "​",
            "style": "IPY_MODEL_5a7ec073dd1443e9bd9004d59f9ea794",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f7930487dfe2475c84b639a8c4a125e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08dbc29fc4684a0fb440fa601fed9725",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33abbee8524e4a6fb5aa643ef95d3e8d",
            "value": 2
          }
        },
        "26b3bb3a77754e7594f58cbc4f18c8b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d54f33770c1948cf965880eb7073b254",
            "placeholder": "​",
            "style": "IPY_MODEL_71659ba52c584e98b62aa8ef269ecfe2",
            "value": " 2/2 [02:13&lt;00:00, 62.70s/it]"
          }
        },
        "e396fac6f85645b1a8bcb1c03e4f0775": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d19cf0e2c25c4a638e48d61a60aaafde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a7ec073dd1443e9bd9004d59f9ea794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08dbc29fc4684a0fb440fa601fed9725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33abbee8524e4a6fb5aa643ef95d3e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d54f33770c1948cf965880eb7073b254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71659ba52c584e98b62aa8ef269ecfe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ae8172d14364db9b0140b8ec69ae40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97821f2d02954ba6b941d81bd4700108",
              "IPY_MODEL_1f8d855fd3b1493e8180be435dd008b7",
              "IPY_MODEL_16a6f2231759437dad618e46562c58ed"
            ],
            "layout": "IPY_MODEL_457367d64d2348738a885922804fe715"
          }
        },
        "97821f2d02954ba6b941d81bd4700108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c899b6a5e57e4a219e2c234f1d81f2e6",
            "placeholder": "​",
            "style": "IPY_MODEL_0e2ce7fd70124db6a55754cb968e28c6",
            "value": "Map: 100%"
          }
        },
        "1f8d855fd3b1493e8180be435dd008b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ec4c386e8ac4054a7e9936246cdd750",
            "max": 46801,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_246ec69d4f8d40afaac55047d2c009c3",
            "value": 46801
          }
        },
        "16a6f2231759437dad618e46562c58ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5a8603cfdc6487cac9dd20a183852d5",
            "placeholder": "​",
            "style": "IPY_MODEL_cf464164e0164654a188cf37bf750454",
            "value": " 46801/46801 [01:38&lt;00:00, 854.87 examples/s]"
          }
        },
        "457367d64d2348738a885922804fe715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c899b6a5e57e4a219e2c234f1d81f2e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2ce7fd70124db6a55754cb968e28c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ec4c386e8ac4054a7e9936246cdd750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "246ec69d4f8d40afaac55047d2c009c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5a8603cfdc6487cac9dd20a183852d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf464164e0164654a188cf37bf750454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ERyOes1zCVA"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets accelerate peft bitsandbytes sentencepiece huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from datasets import load_dataset\n",
        "from accelerate import Accelerator\n",
        "import json"
      ],
      "metadata": {
        "id": "Vx48-rcBzeFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_MODEL = \"stabilityai/stablelm-tuned-alpha-3b\"  # choose a <7B model\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    load_in_8bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "# Prepare model for LoRA/k-bit training\n",
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "3e069610f4b6446a98b4a4e4960bd70f",
            "5221ca53dc7d4188b50776714ac8ecdb",
            "f7930487dfe2475c84b639a8c4a125e2",
            "26b3bb3a77754e7594f58cbc4f18c8b4",
            "e396fac6f85645b1a8bcb1c03e4f0775",
            "d19cf0e2c25c4a638e48d61a60aaafde",
            "5a7ec073dd1443e9bd9004d59f9ea794",
            "08dbc29fc4684a0fb440fa601fed9725",
            "33abbee8524e4a6fb5aa643ef95d3e8d",
            "d54f33770c1948cf965880eb7073b254",
            "71659ba52c584e98b62aa8ef269ecfe2"
          ]
        },
        "id": "Ha5idrZ4zoBb",
        "outputId": "10cf98b1-5305-465c-a34a-b86166967483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e069610f4b6446a98b4a4e4960bd70f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JOUTRgC4fSI",
        "outputId": "25f17243-e96d-4a45-ba37-80ea256bb6c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTNeoXForCausalLM(\n",
            "  (gpt_neox): GPTNeoXModel(\n",
            "    (embed_in): Embedding(50688, 4096)\n",
            "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
            "    (layers): ModuleList(\n",
            "      (0-15): 16 x GPTNeoXLayer(\n",
            "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
            "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
            "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
            "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
            "        (attention): GPTNeoXAttention(\n",
            "          (query_key_value): Linear8bitLt(in_features=4096, out_features=12288, bias=True)\n",
            "          (dense): Linear8bitLt(in_features=4096, out_features=4096, bias=True)\n",
            "        )\n",
            "        (mlp): GPTNeoXMLP(\n",
            "          (dense_h_to_4h): Linear8bitLt(in_features=4096, out_features=16384, bias=True)\n",
            "          (dense_4h_to_h): Linear8bitLt(in_features=16384, out_features=4096, bias=True)\n",
            "          (act): GELUActivation()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
            "    (rotary_emb): GPTNeoXRotaryEmbedding()\n",
            "  )\n",
            "  (embed_out): Linear(in_features=4096, out_features=50688, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"query_key_value\", \"dense\"],  # adjust per model; for some models use ['linear']\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n"
      ],
      "metadata": {
        "id": "O6yBvVEnzpq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "170b6c4d",
        "outputId": "4bc2745a-008e-4080-e5e4-6714289d1279"
      },
      "source": [
        "# Inspect the model's layer names to find the correct target modules\n",
        "for name, module in model.named_modules():\n",
        "    print(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "base_model\n",
            "base_model.model\n",
            "base_model.model.gpt_neox\n",
            "base_model.model.gpt_neox.embed_in\n",
            "base_model.model.gpt_neox.emb_dropout\n",
            "base_model.model.gpt_neox.layers\n",
            "base_model.model.gpt_neox.layers.0\n",
            "base_model.model.gpt_neox.layers.0.input_layernorm\n",
            "base_model.model.gpt_neox.layers.0.post_attention_layernorm\n",
            "base_model.model.gpt_neox.layers.0.post_attention_dropout\n",
            "base_model.model.gpt_neox.layers.0.post_mlp_dropout\n",
            "base_model.model.gpt_neox.layers.0.attention\n",
            "base_model.model.gpt_neox.layers.0.attention.query_key_value\n",
            "base_model.model.gpt_neox.layers.0.attention.query_key_value.base_layer\n",
            "base_model.model.gpt_neox.layers.0.attention.query_key_value.lora_dropout\n",
            "base_model.model.gpt_neox.layers.0.attention.query_key_value.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.0.attention.query_key_value.lora_A\n",
            "base_model.model.gpt_neox.layers.0.attention.query_key_value.lora_A.default\n",
            "base_model.model.gpt_neox.layers.0.attention.query_key_value.lora_B\n",
            "base_model.model.gpt_neox.layers.0.attention.query_key_value.lora_B.default\n",
            "base_model.model.gpt_neox.layers.0.attention.query_key_value.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.0.attention.query_key_value.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.0.attention.query_key_value.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.0.attention.dense\n",
            "base_model.model.gpt_neox.layers.0.attention.dense.base_layer\n",
            "base_model.model.gpt_neox.layers.0.attention.dense.lora_dropout\n",
            "base_model.model.gpt_neox.layers.0.attention.dense.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.0.attention.dense.lora_A\n",
            "base_model.model.gpt_neox.layers.0.attention.dense.lora_A.default\n",
            "base_model.model.gpt_neox.layers.0.attention.dense.lora_B\n",
            "base_model.model.gpt_neox.layers.0.attention.dense.lora_B.default\n",
            "base_model.model.gpt_neox.layers.0.attention.dense.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.0.attention.dense.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.0.attention.dense.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.0.mlp\n",
            "base_model.model.gpt_neox.layers.0.mlp.dense_h_to_4h\n",
            "base_model.model.gpt_neox.layers.0.mlp.dense_4h_to_h\n",
            "base_model.model.gpt_neox.layers.0.mlp.act\n",
            "base_model.model.gpt_neox.layers.1\n",
            "base_model.model.gpt_neox.layers.1.input_layernorm\n",
            "base_model.model.gpt_neox.layers.1.post_attention_layernorm\n",
            "base_model.model.gpt_neox.layers.1.post_attention_dropout\n",
            "base_model.model.gpt_neox.layers.1.post_mlp_dropout\n",
            "base_model.model.gpt_neox.layers.1.attention\n",
            "base_model.model.gpt_neox.layers.1.attention.query_key_value\n",
            "base_model.model.gpt_neox.layers.1.attention.query_key_value.base_layer\n",
            "base_model.model.gpt_neox.layers.1.attention.query_key_value.lora_dropout\n",
            "base_model.model.gpt_neox.layers.1.attention.query_key_value.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.1.attention.query_key_value.lora_A\n",
            "base_model.model.gpt_neox.layers.1.attention.query_key_value.lora_A.default\n",
            "base_model.model.gpt_neox.layers.1.attention.query_key_value.lora_B\n",
            "base_model.model.gpt_neox.layers.1.attention.query_key_value.lora_B.default\n",
            "base_model.model.gpt_neox.layers.1.attention.query_key_value.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.1.attention.query_key_value.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.1.attention.query_key_value.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.1.attention.dense\n",
            "base_model.model.gpt_neox.layers.1.attention.dense.base_layer\n",
            "base_model.model.gpt_neox.layers.1.attention.dense.lora_dropout\n",
            "base_model.model.gpt_neox.layers.1.attention.dense.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.1.attention.dense.lora_A\n",
            "base_model.model.gpt_neox.layers.1.attention.dense.lora_A.default\n",
            "base_model.model.gpt_neox.layers.1.attention.dense.lora_B\n",
            "base_model.model.gpt_neox.layers.1.attention.dense.lora_B.default\n",
            "base_model.model.gpt_neox.layers.1.attention.dense.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.1.attention.dense.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.1.attention.dense.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.1.mlp\n",
            "base_model.model.gpt_neox.layers.1.mlp.dense_h_to_4h\n",
            "base_model.model.gpt_neox.layers.1.mlp.dense_4h_to_h\n",
            "base_model.model.gpt_neox.layers.1.mlp.act\n",
            "base_model.model.gpt_neox.layers.2\n",
            "base_model.model.gpt_neox.layers.2.input_layernorm\n",
            "base_model.model.gpt_neox.layers.2.post_attention_layernorm\n",
            "base_model.model.gpt_neox.layers.2.post_attention_dropout\n",
            "base_model.model.gpt_neox.layers.2.post_mlp_dropout\n",
            "base_model.model.gpt_neox.layers.2.attention\n",
            "base_model.model.gpt_neox.layers.2.attention.query_key_value\n",
            "base_model.model.gpt_neox.layers.2.attention.query_key_value.base_layer\n",
            "base_model.model.gpt_neox.layers.2.attention.query_key_value.lora_dropout\n",
            "base_model.model.gpt_neox.layers.2.attention.query_key_value.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.2.attention.query_key_value.lora_A\n",
            "base_model.model.gpt_neox.layers.2.attention.query_key_value.lora_A.default\n",
            "base_model.model.gpt_neox.layers.2.attention.query_key_value.lora_B\n",
            "base_model.model.gpt_neox.layers.2.attention.query_key_value.lora_B.default\n",
            "base_model.model.gpt_neox.layers.2.attention.query_key_value.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.2.attention.query_key_value.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.2.attention.query_key_value.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.2.attention.dense\n",
            "base_model.model.gpt_neox.layers.2.attention.dense.base_layer\n",
            "base_model.model.gpt_neox.layers.2.attention.dense.lora_dropout\n",
            "base_model.model.gpt_neox.layers.2.attention.dense.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.2.attention.dense.lora_A\n",
            "base_model.model.gpt_neox.layers.2.attention.dense.lora_A.default\n",
            "base_model.model.gpt_neox.layers.2.attention.dense.lora_B\n",
            "base_model.model.gpt_neox.layers.2.attention.dense.lora_B.default\n",
            "base_model.model.gpt_neox.layers.2.attention.dense.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.2.attention.dense.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.2.attention.dense.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.2.mlp\n",
            "base_model.model.gpt_neox.layers.2.mlp.dense_h_to_4h\n",
            "base_model.model.gpt_neox.layers.2.mlp.dense_4h_to_h\n",
            "base_model.model.gpt_neox.layers.2.mlp.act\n",
            "base_model.model.gpt_neox.layers.3\n",
            "base_model.model.gpt_neox.layers.3.input_layernorm\n",
            "base_model.model.gpt_neox.layers.3.post_attention_layernorm\n",
            "base_model.model.gpt_neox.layers.3.post_attention_dropout\n",
            "base_model.model.gpt_neox.layers.3.post_mlp_dropout\n",
            "base_model.model.gpt_neox.layers.3.attention\n",
            "base_model.model.gpt_neox.layers.3.attention.query_key_value\n",
            "base_model.model.gpt_neox.layers.3.attention.query_key_value.base_layer\n",
            "base_model.model.gpt_neox.layers.3.attention.query_key_value.lora_dropout\n",
            "base_model.model.gpt_neox.layers.3.attention.query_key_value.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.3.attention.query_key_value.lora_A\n",
            "base_model.model.gpt_neox.layers.3.attention.query_key_value.lora_A.default\n",
            "base_model.model.gpt_neox.layers.3.attention.query_key_value.lora_B\n",
            "base_model.model.gpt_neox.layers.3.attention.query_key_value.lora_B.default\n",
            "base_model.model.gpt_neox.layers.3.attention.query_key_value.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.3.attention.query_key_value.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.3.attention.query_key_value.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.3.attention.dense\n",
            "base_model.model.gpt_neox.layers.3.attention.dense.base_layer\n",
            "base_model.model.gpt_neox.layers.3.attention.dense.lora_dropout\n",
            "base_model.model.gpt_neox.layers.3.attention.dense.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.3.attention.dense.lora_A\n",
            "base_model.model.gpt_neox.layers.3.attention.dense.lora_A.default\n",
            "base_model.model.gpt_neox.layers.3.attention.dense.lora_B\n",
            "base_model.model.gpt_neox.layers.3.attention.dense.lora_B.default\n",
            "base_model.model.gpt_neox.layers.3.attention.dense.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.3.attention.dense.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.3.attention.dense.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.3.mlp\n",
            "base_model.model.gpt_neox.layers.3.mlp.dense_h_to_4h\n",
            "base_model.model.gpt_neox.layers.3.mlp.dense_4h_to_h\n",
            "base_model.model.gpt_neox.layers.3.mlp.act\n",
            "base_model.model.gpt_neox.layers.4\n",
            "base_model.model.gpt_neox.layers.4.input_layernorm\n",
            "base_model.model.gpt_neox.layers.4.post_attention_layernorm\n",
            "base_model.model.gpt_neox.layers.4.post_attention_dropout\n",
            "base_model.model.gpt_neox.layers.4.post_mlp_dropout\n",
            "base_model.model.gpt_neox.layers.4.attention\n",
            "base_model.model.gpt_neox.layers.4.attention.query_key_value\n",
            "base_model.model.gpt_neox.layers.4.attention.query_key_value.base_layer\n",
            "base_model.model.gpt_neox.layers.4.attention.query_key_value.lora_dropout\n",
            "base_model.model.gpt_neox.layers.4.attention.query_key_value.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.4.attention.query_key_value.lora_A\n",
            "base_model.model.gpt_neox.layers.4.attention.query_key_value.lora_A.default\n",
            "base_model.model.gpt_neox.layers.4.attention.query_key_value.lora_B\n",
            "base_model.model.gpt_neox.layers.4.attention.query_key_value.lora_B.default\n",
            "base_model.model.gpt_neox.layers.4.attention.query_key_value.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.4.attention.query_key_value.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.4.attention.query_key_value.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.4.attention.dense\n",
            "base_model.model.gpt_neox.layers.4.attention.dense.base_layer\n",
            "base_model.model.gpt_neox.layers.4.attention.dense.lora_dropout\n",
            "base_model.model.gpt_neox.layers.4.attention.dense.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.4.attention.dense.lora_A\n",
            "base_model.model.gpt_neox.layers.4.attention.dense.lora_A.default\n",
            "base_model.model.gpt_neox.layers.4.attention.dense.lora_B\n",
            "base_model.model.gpt_neox.layers.4.attention.dense.lora_B.default\n",
            "base_model.model.gpt_neox.layers.4.attention.dense.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.4.attention.dense.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.4.attention.dense.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.4.mlp\n",
            "base_model.model.gpt_neox.layers.4.mlp.dense_h_to_4h\n",
            "base_model.model.gpt_neox.layers.4.mlp.dense_4h_to_h\n",
            "base_model.model.gpt_neox.layers.4.mlp.act\n",
            "base_model.model.gpt_neox.layers.5\n",
            "base_model.model.gpt_neox.layers.5.input_layernorm\n",
            "base_model.model.gpt_neox.layers.5.post_attention_layernorm\n",
            "base_model.model.gpt_neox.layers.5.post_attention_dropout\n",
            "base_model.model.gpt_neox.layers.5.post_mlp_dropout\n",
            "base_model.model.gpt_neox.layers.5.attention\n",
            "base_model.model.gpt_neox.layers.5.attention.query_key_value\n",
            "base_model.model.gpt_neox.layers.5.attention.query_key_value.base_layer\n",
            "base_model.model.gpt_neox.layers.5.attention.query_key_value.lora_dropout\n",
            "base_model.model.gpt_neox.layers.5.attention.query_key_value.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.5.attention.query_key_value.lora_A\n",
            "base_model.model.gpt_neox.layers.5.attention.query_key_value.lora_A.default\n",
            "base_model.model.gpt_neox.layers.5.attention.query_key_value.lora_B\n",
            "base_model.model.gpt_neox.layers.5.attention.query_key_value.lora_B.default\n",
            "base_model.model.gpt_neox.layers.5.attention.query_key_value.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.5.attention.query_key_value.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.5.attention.query_key_value.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.5.attention.dense\n",
            "base_model.model.gpt_neox.layers.5.attention.dense.base_layer\n",
            "base_model.model.gpt_neox.layers.5.attention.dense.lora_dropout\n",
            "base_model.model.gpt_neox.layers.5.attention.dense.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.5.attention.dense.lora_A\n",
            "base_model.model.gpt_neox.layers.5.attention.dense.lora_A.default\n",
            "base_model.model.gpt_neox.layers.5.attention.dense.lora_B\n",
            "base_model.model.gpt_neox.layers.5.attention.dense.lora_B.default\n",
            "base_model.model.gpt_neox.layers.5.attention.dense.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.5.attention.dense.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.5.attention.dense.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.5.mlp\n",
            "base_model.model.gpt_neox.layers.5.mlp.dense_h_to_4h\n",
            "base_model.model.gpt_neox.layers.5.mlp.dense_4h_to_h\n",
            "base_model.model.gpt_neox.layers.5.mlp.act\n",
            "base_model.model.gpt_neox.layers.6\n",
            "base_model.model.gpt_neox.layers.6.input_layernorm\n",
            "base_model.model.gpt_neox.layers.6.post_attention_layernorm\n",
            "base_model.model.gpt_neox.layers.6.post_attention_dropout\n",
            "base_model.model.gpt_neox.layers.6.post_mlp_dropout\n",
            "base_model.model.gpt_neox.layers.6.attention\n",
            "base_model.model.gpt_neox.layers.6.attention.query_key_value\n",
            "base_model.model.gpt_neox.layers.6.attention.query_key_value.base_layer\n",
            "base_model.model.gpt_neox.layers.6.attention.query_key_value.lora_dropout\n",
            "base_model.model.gpt_neox.layers.6.attention.query_key_value.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.6.attention.query_key_value.lora_A\n",
            "base_model.model.gpt_neox.layers.6.attention.query_key_value.lora_A.default\n",
            "base_model.model.gpt_neox.layers.6.attention.query_key_value.lora_B\n",
            "base_model.model.gpt_neox.layers.6.attention.query_key_value.lora_B.default\n",
            "base_model.model.gpt_neox.layers.6.attention.query_key_value.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.6.attention.query_key_value.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.6.attention.query_key_value.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.6.attention.dense\n",
            "base_model.model.gpt_neox.layers.6.attention.dense.base_layer\n",
            "base_model.model.gpt_neox.layers.6.attention.dense.lora_dropout\n",
            "base_model.model.gpt_neox.layers.6.attention.dense.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.6.attention.dense.lora_A\n",
            "base_model.model.gpt_neox.layers.6.attention.dense.lora_A.default\n",
            "base_model.model.gpt_neox.layers.6.attention.dense.lora_B\n",
            "base_model.model.gpt_neox.layers.6.attention.dense.lora_B.default\n",
            "base_model.model.gpt_neox.layers.6.attention.dense.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.6.attention.dense.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.6.attention.dense.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.6.mlp\n",
            "base_model.model.gpt_neox.layers.6.mlp.dense_h_to_4h\n",
            "base_model.model.gpt_neox.layers.6.mlp.dense_4h_to_h\n",
            "base_model.model.gpt_neox.layers.6.mlp.act\n",
            "base_model.model.gpt_neox.layers.7\n",
            "base_model.model.gpt_neox.layers.7.input_layernorm\n",
            "base_model.model.gpt_neox.layers.7.post_attention_layernorm\n",
            "base_model.model.gpt_neox.layers.7.post_attention_dropout\n",
            "base_model.model.gpt_neox.layers.7.post_mlp_dropout\n",
            "base_model.model.gpt_neox.layers.7.attention\n",
            "base_model.model.gpt_neox.layers.7.attention.query_key_value\n",
            "base_model.model.gpt_neox.layers.7.attention.query_key_value.base_layer\n",
            "base_model.model.gpt_neox.layers.7.attention.query_key_value.lora_dropout\n",
            "base_model.model.gpt_neox.layers.7.attention.query_key_value.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.7.attention.query_key_value.lora_A\n",
            "base_model.model.gpt_neox.layers.7.attention.query_key_value.lora_A.default\n",
            "base_model.model.gpt_neox.layers.7.attention.query_key_value.lora_B\n",
            "base_model.model.gpt_neox.layers.7.attention.query_key_value.lora_B.default\n",
            "base_model.model.gpt_neox.layers.7.attention.query_key_value.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.7.attention.query_key_value.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.7.attention.query_key_value.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.7.attention.dense\n",
            "base_model.model.gpt_neox.layers.7.attention.dense.base_layer\n",
            "base_model.model.gpt_neox.layers.7.attention.dense.lora_dropout\n",
            "base_model.model.gpt_neox.layers.7.attention.dense.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.7.attention.dense.lora_A\n",
            "base_model.model.gpt_neox.layers.7.attention.dense.lora_A.default\n",
            "base_model.model.gpt_neox.layers.7.attention.dense.lora_B\n",
            "base_model.model.gpt_neox.layers.7.attention.dense.lora_B.default\n",
            "base_model.model.gpt_neox.layers.7.attention.dense.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.7.attention.dense.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.7.attention.dense.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.7.mlp\n",
            "base_model.model.gpt_neox.layers.7.mlp.dense_h_to_4h\n",
            "base_model.model.gpt_neox.layers.7.mlp.dense_4h_to_h\n",
            "base_model.model.gpt_neox.layers.7.mlp.act\n",
            "base_model.model.gpt_neox.layers.8\n",
            "base_model.model.gpt_neox.layers.8.input_layernorm\n",
            "base_model.model.gpt_neox.layers.8.post_attention_layernorm\n",
            "base_model.model.gpt_neox.layers.8.post_attention_dropout\n",
            "base_model.model.gpt_neox.layers.8.post_mlp_dropout\n",
            "base_model.model.gpt_neox.layers.8.attention\n",
            "base_model.model.gpt_neox.layers.8.attention.query_key_value\n",
            "base_model.model.gpt_neox.layers.8.attention.query_key_value.base_layer\n",
            "base_model.model.gpt_neox.layers.8.attention.query_key_value.lora_dropout\n",
            "base_model.model.gpt_neox.layers.8.attention.query_key_value.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.8.attention.query_key_value.lora_A\n",
            "base_model.model.gpt_neox.layers.8.attention.query_key_value.lora_A.default\n",
            "base_model.model.gpt_neox.layers.8.attention.query_key_value.lora_B\n",
            "base_model.model.gpt_neox.layers.8.attention.query_key_value.lora_B.default\n",
            "base_model.model.gpt_neox.layers.8.attention.query_key_value.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.8.attention.query_key_value.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.8.attention.query_key_value.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.8.attention.dense\n",
            "base_model.model.gpt_neox.layers.8.attention.dense.base_layer\n",
            "base_model.model.gpt_neox.layers.8.attention.dense.lora_dropout\n",
            "base_model.model.gpt_neox.layers.8.attention.dense.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.8.attention.dense.lora_A\n",
            "base_model.model.gpt_neox.layers.8.attention.dense.lora_A.default\n",
            "base_model.model.gpt_neox.layers.8.attention.dense.lora_B\n",
            "base_model.model.gpt_neox.layers.8.attention.dense.lora_B.default\n",
            "base_model.model.gpt_neox.layers.8.attention.dense.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.8.attention.dense.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.8.attention.dense.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.8.mlp\n",
            "base_model.model.gpt_neox.layers.8.mlp.dense_h_to_4h\n",
            "base_model.model.gpt_neox.layers.8.mlp.dense_4h_to_h\n",
            "base_model.model.gpt_neox.layers.8.mlp.act\n",
            "base_model.model.gpt_neox.layers.9\n",
            "base_model.model.gpt_neox.layers.9.input_layernorm\n",
            "base_model.model.gpt_neox.layers.9.post_attention_layernorm\n",
            "base_model.model.gpt_neox.layers.9.post_attention_dropout\n",
            "base_model.model.gpt_neox.layers.9.post_mlp_dropout\n",
            "base_model.model.gpt_neox.layers.9.attention\n",
            "base_model.model.gpt_neox.layers.9.attention.query_key_value\n",
            "base_model.model.gpt_neox.layers.9.attention.query_key_value.base_layer\n",
            "base_model.model.gpt_neox.layers.9.attention.query_key_value.lora_dropout\n",
            "base_model.model.gpt_neox.layers.9.attention.query_key_value.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.9.attention.query_key_value.lora_A\n",
            "base_model.model.gpt_neox.layers.9.attention.query_key_value.lora_A.default\n",
            "base_model.model.gpt_neox.layers.9.attention.query_key_value.lora_B\n",
            "base_model.model.gpt_neox.layers.9.attention.query_key_value.lora_B.default\n",
            "base_model.model.gpt_neox.layers.9.attention.query_key_value.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.9.attention.query_key_value.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.9.attention.query_key_value.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.9.attention.dense\n",
            "base_model.model.gpt_neox.layers.9.attention.dense.base_layer\n",
            "base_model.model.gpt_neox.layers.9.attention.dense.lora_dropout\n",
            "base_model.model.gpt_neox.layers.9.attention.dense.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.9.attention.dense.lora_A\n",
            "base_model.model.gpt_neox.layers.9.attention.dense.lora_A.default\n",
            "base_model.model.gpt_neox.layers.9.attention.dense.lora_B\n",
            "base_model.model.gpt_neox.layers.9.attention.dense.lora_B.default\n",
            "base_model.model.gpt_neox.layers.9.attention.dense.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.9.attention.dense.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.9.attention.dense.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.9.mlp\n",
            "base_model.model.gpt_neox.layers.9.mlp.dense_h_to_4h\n",
            "base_model.model.gpt_neox.layers.9.mlp.dense_4h_to_h\n",
            "base_model.model.gpt_neox.layers.9.mlp.act\n",
            "base_model.model.gpt_neox.layers.10\n",
            "base_model.model.gpt_neox.layers.10.input_layernorm\n",
            "base_model.model.gpt_neox.layers.10.post_attention_layernorm\n",
            "base_model.model.gpt_neox.layers.10.post_attention_dropout\n",
            "base_model.model.gpt_neox.layers.10.post_mlp_dropout\n",
            "base_model.model.gpt_neox.layers.10.attention\n",
            "base_model.model.gpt_neox.layers.10.attention.query_key_value\n",
            "base_model.model.gpt_neox.layers.10.attention.query_key_value.base_layer\n",
            "base_model.model.gpt_neox.layers.10.attention.query_key_value.lora_dropout\n",
            "base_model.model.gpt_neox.layers.10.attention.query_key_value.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.10.attention.query_key_value.lora_A\n",
            "base_model.model.gpt_neox.layers.10.attention.query_key_value.lora_A.default\n",
            "base_model.model.gpt_neox.layers.10.attention.query_key_value.lora_B\n",
            "base_model.model.gpt_neox.layers.10.attention.query_key_value.lora_B.default\n",
            "base_model.model.gpt_neox.layers.10.attention.query_key_value.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.10.attention.query_key_value.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.10.attention.query_key_value.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.10.attention.dense\n",
            "base_model.model.gpt_neox.layers.10.attention.dense.base_layer\n",
            "base_model.model.gpt_neox.layers.10.attention.dense.lora_dropout\n",
            "base_model.model.gpt_neox.layers.10.attention.dense.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.10.attention.dense.lora_A\n",
            "base_model.model.gpt_neox.layers.10.attention.dense.lora_A.default\n",
            "base_model.model.gpt_neox.layers.10.attention.dense.lora_B\n",
            "base_model.model.gpt_neox.layers.10.attention.dense.lora_B.default\n",
            "base_model.model.gpt_neox.layers.10.attention.dense.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.10.attention.dense.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.10.attention.dense.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.10.mlp\n",
            "base_model.model.gpt_neox.layers.10.mlp.dense_h_to_4h\n",
            "base_model.model.gpt_neox.layers.10.mlp.dense_4h_to_h\n",
            "base_model.model.gpt_neox.layers.10.mlp.act\n",
            "base_model.model.gpt_neox.layers.11\n",
            "base_model.model.gpt_neox.layers.11.input_layernorm\n",
            "base_model.model.gpt_neox.layers.11.post_attention_layernorm\n",
            "base_model.model.gpt_neox.layers.11.post_attention_dropout\n",
            "base_model.model.gpt_neox.layers.11.post_mlp_dropout\n",
            "base_model.model.gpt_neox.layers.11.attention\n",
            "base_model.model.gpt_neox.layers.11.attention.query_key_value\n",
            "base_model.model.gpt_neox.layers.11.attention.query_key_value.base_layer\n",
            "base_model.model.gpt_neox.layers.11.attention.query_key_value.lora_dropout\n",
            "base_model.model.gpt_neox.layers.11.attention.query_key_value.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.11.attention.query_key_value.lora_A\n",
            "base_model.model.gpt_neox.layers.11.attention.query_key_value.lora_A.default\n",
            "base_model.model.gpt_neox.layers.11.attention.query_key_value.lora_B\n",
            "base_model.model.gpt_neox.layers.11.attention.query_key_value.lora_B.default\n",
            "base_model.model.gpt_neox.layers.11.attention.query_key_value.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.11.attention.query_key_value.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.11.attention.query_key_value.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.11.attention.dense\n",
            "base_model.model.gpt_neox.layers.11.attention.dense.base_layer\n",
            "base_model.model.gpt_neox.layers.11.attention.dense.lora_dropout\n",
            "base_model.model.gpt_neox.layers.11.attention.dense.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.11.attention.dense.lora_A\n",
            "base_model.model.gpt_neox.layers.11.attention.dense.lora_A.default\n",
            "base_model.model.gpt_neox.layers.11.attention.dense.lora_B\n",
            "base_model.model.gpt_neox.layers.11.attention.dense.lora_B.default\n",
            "base_model.model.gpt_neox.layers.11.attention.dense.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.11.attention.dense.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.11.attention.dense.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.11.mlp\n",
            "base_model.model.gpt_neox.layers.11.mlp.dense_h_to_4h\n",
            "base_model.model.gpt_neox.layers.11.mlp.dense_4h_to_h\n",
            "base_model.model.gpt_neox.layers.11.mlp.act\n",
            "base_model.model.gpt_neox.layers.12\n",
            "base_model.model.gpt_neox.layers.12.input_layernorm\n",
            "base_model.model.gpt_neox.layers.12.post_attention_layernorm\n",
            "base_model.model.gpt_neox.layers.12.post_attention_dropout\n",
            "base_model.model.gpt_neox.layers.12.post_mlp_dropout\n",
            "base_model.model.gpt_neox.layers.12.attention\n",
            "base_model.model.gpt_neox.layers.12.attention.query_key_value\n",
            "base_model.model.gpt_neox.layers.12.attention.query_key_value.base_layer\n",
            "base_model.model.gpt_neox.layers.12.attention.query_key_value.lora_dropout\n",
            "base_model.model.gpt_neox.layers.12.attention.query_key_value.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.12.attention.query_key_value.lora_A\n",
            "base_model.model.gpt_neox.layers.12.attention.query_key_value.lora_A.default\n",
            "base_model.model.gpt_neox.layers.12.attention.query_key_value.lora_B\n",
            "base_model.model.gpt_neox.layers.12.attention.query_key_value.lora_B.default\n",
            "base_model.model.gpt_neox.layers.12.attention.query_key_value.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.12.attention.query_key_value.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.12.attention.query_key_value.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.12.attention.dense\n",
            "base_model.model.gpt_neox.layers.12.attention.dense.base_layer\n",
            "base_model.model.gpt_neox.layers.12.attention.dense.lora_dropout\n",
            "base_model.model.gpt_neox.layers.12.attention.dense.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.12.attention.dense.lora_A\n",
            "base_model.model.gpt_neox.layers.12.attention.dense.lora_A.default\n",
            "base_model.model.gpt_neox.layers.12.attention.dense.lora_B\n",
            "base_model.model.gpt_neox.layers.12.attention.dense.lora_B.default\n",
            "base_model.model.gpt_neox.layers.12.attention.dense.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.12.attention.dense.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.12.attention.dense.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.12.mlp\n",
            "base_model.model.gpt_neox.layers.12.mlp.dense_h_to_4h\n",
            "base_model.model.gpt_neox.layers.12.mlp.dense_4h_to_h\n",
            "base_model.model.gpt_neox.layers.12.mlp.act\n",
            "base_model.model.gpt_neox.layers.13\n",
            "base_model.model.gpt_neox.layers.13.input_layernorm\n",
            "base_model.model.gpt_neox.layers.13.post_attention_layernorm\n",
            "base_model.model.gpt_neox.layers.13.post_attention_dropout\n",
            "base_model.model.gpt_neox.layers.13.post_mlp_dropout\n",
            "base_model.model.gpt_neox.layers.13.attention\n",
            "base_model.model.gpt_neox.layers.13.attention.query_key_value\n",
            "base_model.model.gpt_neox.layers.13.attention.query_key_value.base_layer\n",
            "base_model.model.gpt_neox.layers.13.attention.query_key_value.lora_dropout\n",
            "base_model.model.gpt_neox.layers.13.attention.query_key_value.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.13.attention.query_key_value.lora_A\n",
            "base_model.model.gpt_neox.layers.13.attention.query_key_value.lora_A.default\n",
            "base_model.model.gpt_neox.layers.13.attention.query_key_value.lora_B\n",
            "base_model.model.gpt_neox.layers.13.attention.query_key_value.lora_B.default\n",
            "base_model.model.gpt_neox.layers.13.attention.query_key_value.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.13.attention.query_key_value.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.13.attention.query_key_value.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.13.attention.dense\n",
            "base_model.model.gpt_neox.layers.13.attention.dense.base_layer\n",
            "base_model.model.gpt_neox.layers.13.attention.dense.lora_dropout\n",
            "base_model.model.gpt_neox.layers.13.attention.dense.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.13.attention.dense.lora_A\n",
            "base_model.model.gpt_neox.layers.13.attention.dense.lora_A.default\n",
            "base_model.model.gpt_neox.layers.13.attention.dense.lora_B\n",
            "base_model.model.gpt_neox.layers.13.attention.dense.lora_B.default\n",
            "base_model.model.gpt_neox.layers.13.attention.dense.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.13.attention.dense.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.13.attention.dense.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.13.mlp\n",
            "base_model.model.gpt_neox.layers.13.mlp.dense_h_to_4h\n",
            "base_model.model.gpt_neox.layers.13.mlp.dense_4h_to_h\n",
            "base_model.model.gpt_neox.layers.13.mlp.act\n",
            "base_model.model.gpt_neox.layers.14\n",
            "base_model.model.gpt_neox.layers.14.input_layernorm\n",
            "base_model.model.gpt_neox.layers.14.post_attention_layernorm\n",
            "base_model.model.gpt_neox.layers.14.post_attention_dropout\n",
            "base_model.model.gpt_neox.layers.14.post_mlp_dropout\n",
            "base_model.model.gpt_neox.layers.14.attention\n",
            "base_model.model.gpt_neox.layers.14.attention.query_key_value\n",
            "base_model.model.gpt_neox.layers.14.attention.query_key_value.base_layer\n",
            "base_model.model.gpt_neox.layers.14.attention.query_key_value.lora_dropout\n",
            "base_model.model.gpt_neox.layers.14.attention.query_key_value.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.14.attention.query_key_value.lora_A\n",
            "base_model.model.gpt_neox.layers.14.attention.query_key_value.lora_A.default\n",
            "base_model.model.gpt_neox.layers.14.attention.query_key_value.lora_B\n",
            "base_model.model.gpt_neox.layers.14.attention.query_key_value.lora_B.default\n",
            "base_model.model.gpt_neox.layers.14.attention.query_key_value.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.14.attention.query_key_value.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.14.attention.query_key_value.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.14.attention.dense\n",
            "base_model.model.gpt_neox.layers.14.attention.dense.base_layer\n",
            "base_model.model.gpt_neox.layers.14.attention.dense.lora_dropout\n",
            "base_model.model.gpt_neox.layers.14.attention.dense.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.14.attention.dense.lora_A\n",
            "base_model.model.gpt_neox.layers.14.attention.dense.lora_A.default\n",
            "base_model.model.gpt_neox.layers.14.attention.dense.lora_B\n",
            "base_model.model.gpt_neox.layers.14.attention.dense.lora_B.default\n",
            "base_model.model.gpt_neox.layers.14.attention.dense.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.14.attention.dense.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.14.attention.dense.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.14.mlp\n",
            "base_model.model.gpt_neox.layers.14.mlp.dense_h_to_4h\n",
            "base_model.model.gpt_neox.layers.14.mlp.dense_4h_to_h\n",
            "base_model.model.gpt_neox.layers.14.mlp.act\n",
            "base_model.model.gpt_neox.layers.15\n",
            "base_model.model.gpt_neox.layers.15.input_layernorm\n",
            "base_model.model.gpt_neox.layers.15.post_attention_layernorm\n",
            "base_model.model.gpt_neox.layers.15.post_attention_dropout\n",
            "base_model.model.gpt_neox.layers.15.post_mlp_dropout\n",
            "base_model.model.gpt_neox.layers.15.attention\n",
            "base_model.model.gpt_neox.layers.15.attention.query_key_value\n",
            "base_model.model.gpt_neox.layers.15.attention.query_key_value.base_layer\n",
            "base_model.model.gpt_neox.layers.15.attention.query_key_value.lora_dropout\n",
            "base_model.model.gpt_neox.layers.15.attention.query_key_value.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.15.attention.query_key_value.lora_A\n",
            "base_model.model.gpt_neox.layers.15.attention.query_key_value.lora_A.default\n",
            "base_model.model.gpt_neox.layers.15.attention.query_key_value.lora_B\n",
            "base_model.model.gpt_neox.layers.15.attention.query_key_value.lora_B.default\n",
            "base_model.model.gpt_neox.layers.15.attention.query_key_value.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.15.attention.query_key_value.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.15.attention.query_key_value.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.15.attention.dense\n",
            "base_model.model.gpt_neox.layers.15.attention.dense.base_layer\n",
            "base_model.model.gpt_neox.layers.15.attention.dense.lora_dropout\n",
            "base_model.model.gpt_neox.layers.15.attention.dense.lora_dropout.default\n",
            "base_model.model.gpt_neox.layers.15.attention.dense.lora_A\n",
            "base_model.model.gpt_neox.layers.15.attention.dense.lora_A.default\n",
            "base_model.model.gpt_neox.layers.15.attention.dense.lora_B\n",
            "base_model.model.gpt_neox.layers.15.attention.dense.lora_B.default\n",
            "base_model.model.gpt_neox.layers.15.attention.dense.lora_embedding_A\n",
            "base_model.model.gpt_neox.layers.15.attention.dense.lora_embedding_B\n",
            "base_model.model.gpt_neox.layers.15.attention.dense.lora_magnitude_vector\n",
            "base_model.model.gpt_neox.layers.15.mlp\n",
            "base_model.model.gpt_neox.layers.15.mlp.dense_h_to_4h\n",
            "base_model.model.gpt_neox.layers.15.mlp.dense_4h_to_h\n",
            "base_model.model.gpt_neox.layers.15.mlp.act\n",
            "base_model.model.gpt_neox.final_layer_norm\n",
            "base_model.model.gpt_neox.rotary_emb\n",
            "base_model.model.embed_out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ds = load_dataset(\"lavita/AlpaCare-MedInstruct-52k\")\n",
        "\n",
        "train_val_test = ds[\"train\"].train_test_split(test_size=0.10, seed=42)\n",
        "train_ds = train_val_test[\"train\"]\n",
        "temp_ds = train_val_test[\"test\"]\n",
        "\n",
        "val_test_split = temp_ds.train_test_split(test_size=0.5, seed=42)\n",
        "val_ds = val_test_split[\"train\"]\n",
        "test_ds = val_test_split[\"test\"]\n",
        "\n",
        "print(\"Train size:\", len(train_ds))\n",
        "print(\"Validation size:\", len(val_ds))\n",
        "print(\"Test size:\", len(test_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RICCWXKPzwEF",
        "outputId": "e7587e7b-4f7b-4996-eb47-2602f7eaa2aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 46801\n",
            "Validation size: 2600\n",
            "Test size: 2601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_fn(example):\n",
        "    inst = example.get(\"instruction\") or example.get(\"prompt\") or \"\"\n",
        "    resp = example.get(\"response\") or example.get(\"output\") or \"\"\n",
        "    prompt = f\"Instruction: {inst}\\n\\nResponse: {resp}\"\n",
        "    tokenized = tokenizer(prompt, truncation=True, max_length=512)\n",
        "    return tokenized\n",
        "\n",
        "# Apply preprocessing\n",
        "train_ds = train_ds.map(lambda ex: preprocess_fn(ex), remove_columns=train_ds.column_names)\n",
        "val_ds   = val_ds.map(lambda ex: preprocess_fn(ex), remove_columns=val_ds.column_names)\n",
        "test_ds  = test_ds.map(lambda ex: preprocess_fn(ex), remove_columns=test_ds.column_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2ae8172d14364db9b0140b8ec69ae40f",
            "97821f2d02954ba6b941d81bd4700108",
            "1f8d855fd3b1493e8180be435dd008b7",
            "16a6f2231759437dad618e46562c58ed",
            "457367d64d2348738a885922804fe715",
            "c899b6a5e57e4a219e2c234f1d81f2e6",
            "0e2ce7fd70124db6a55754cb968e28c6",
            "8ec4c386e8ac4054a7e9936246cdd750",
            "246ec69d4f8d40afaac55047d2c009c3",
            "b5a8603cfdc6487cac9dd20a183852d5",
            "cf464164e0164654a188cf37bf750454"
          ]
        },
        "id": "oc76bKAqz4r_",
        "outputId": "216f4fdd-171e-409c-bbf6-6405f4415e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/46801 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ae8172d14364db9b0140b8ec69ae40f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "iFH2uaSp6Wa1",
        "outputId": "f746fc13-f13c-4807-a78a-2f5a531ef845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Downloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.2\n",
            "    Uninstalling transformers-4.56.2:\n",
            "      Successfully uninstalled transformers-4.56.2\n",
            "Successfully installed transformers-4.57.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "3d71c70f619b44b3a5c7294c896a8ab1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adapter_dir = \"adapters/alpacare_lora\"\n",
        "model.save_pretrained(adapter_dir)\n",
        "tokenizer.save_pretrained(adapter_dir)\n",
        "\n",
        "# Optional: Zip for download\n",
        "!zip -r alpacare_lora_adapter.zip adapters/alpacare_lora\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaGrYVi4z_lv",
        "outputId": "0f01cafd-d2c6-45db-a963-187cd0e3a95f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: adapters/alpacare_lora/ (stored 0%)\n",
            "  adding: adapters/alpacare_lora/special_tokens_map.json (deflated 75%)\n",
            "  adding: adapters/alpacare_lora/tokenizer_config.json (deflated 92%)\n",
            "  adding: adapters/alpacare_lora/README.md (deflated 66%)\n",
            "  adding: adapters/alpacare_lora/adapter_config.json (deflated 55%)\n",
            "  adding: adapters/alpacare_lora/adapter_model.safetensors (deflated 69%)\n",
            "  adding: adapters/alpacare_lora/tokenizer.json (deflated 81%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"alpacare_lora_adapter.zip\")\n",
        "# or save to drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !cp -r adapters/alpacare_lora /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RESfoft30DJc",
        "outputId": "18d00e93-b05f-4adf-d9bc-c18140093588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0c3320cd-7ef4-45ed-ac2c-94dcd7bc584f\", \"alpacare_lora_adapter.zip\", 4511649)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --ClearOutputPreprocessor.enabled=True --to notebook --inplace \"colab_finetune.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8JxXy8oewjf",
        "outputId": "068b9089-1127-4ef9-bfcc-c5ba13f93fd0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] WARNING | pattern 'colab_finetune.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--coalesce-streams\n",
            "    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    Overwrite base name use for output files.\n",
            "                Supports pattern replacements '{notebook_name}'.\n",
            "    Default: '{notebook_name}'\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}